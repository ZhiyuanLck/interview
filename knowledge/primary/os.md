# 操作系统

## 进程

1. 进程和线程的区别

    - 进程是一个正在执行程序的实例，是资源调度的基本单位，用于实现操作系统的并发；
      线程也可以看做轻量级的进程，是CPU调度的基本单位
    - 进程拥有一个或多个线程，线程只属于一个进程
    - 进程在执行过程中拥有独立的虚拟内存空间，因此进程间是相互隔离的；同一进程中的
      不同线程共享当前进程的内存空间和所有的资源，这些线程间是没有保护的，一个线程
      甚至可以访问另一个线程的堆栈和地址
    - 每个进程在进程表中有对应的表项，里面存储着进程管理相关字段，比如寄存器、程序
      计数器、程序状态字、堆栈指针、程序状态等，存储管理相关字段，比如代码段指针、
      数据段指针、堆栈段指针等，文件管理相关字段，比如工作目录、文件描述符、用户ID
      等；用户级线程每个进程中都有一张线程表，所有内核级线程都记录在一张内核中的线
      程表，由于线程共享它所属于的进程的所有资源，进程表表项中只记录程序计数器、寄
      存器、堆栈、线程状态等内容。
    - 进程的创建和撤销需要为其分配或回收资源，比如内存空间，I/O设备，打开的文件的
      等等，而线程基本不持有资源而是直接共享来自进程的资源，因此进程的创建和撤销开
      销更大；进程间的切换同样比线程间的切换开销更大，这主要是因为切换进程时需要同
      步切换页表和虚拟内存，这会使TLB中对应的缓存失效从而降低了命中率，从而使虚拟
      地址转换为物理地址的过程变慢。
    - 同一进程间不同线程的由于共享同一虚拟内存空间使得它们的通信更加容易，而进程间
      的通信则需要专门的手段，比如消息传递、共享内存等
    - 进程间不会相互影响，而一个线程阻塞或挂掉会导致整个进程阻塞或挂掉

1. 进程的切换过程

1. 线程的切换过程

1. 进程间通信
    1. 管道（消息传递）
        - 由`pipe`函数创建，返回两个文件描述符，一个只能读，另一个只能写，即提
          供一个半双工的单向数据流
        - 管道也可以是全双工的，此时它由两个半双工管道组成。
        - 管道只能用于具有亲缘关系的进程之间通信
        - 管道是一种特殊的文件，只存在于内存中
    1. FIFO命名管道（消息传递）
        - FIFO是一个单向数据流，FIFO有路径名与之关联，因此可以用于无亲缘关系进
          程之间的通信
    1. 消息队列
        - 消息队列可以看做一个消息链表，拥有足够权限的进程才可以在队列中放置消
          息或者从队列中取走消息
        - 每个消息都是一个记录，它由发送者赋予一个优先级
        - 消息队列具有随内核的持续性，管道最后一次关闭发生时，管道中的数据将被
          丢弃，而消息队列是独立于发送与接收进程的，进程终止不会导致消息被删除
        - 允许异步事件通知，通过产生一个信号或者创建一个线程执行指定的函数
    1. 信号，用于通知接收进程某个事件已经发生
    1. 共享内存
        - 通过`mmap`函数使多个进程可以访问同一块内存空间
        - 共享内存是IPC中最快的，因为进程间的数据传递无需再通过内核传递
        - 信号量通常和共享内存一起使用用来同步不同进程对共享内存的访问
    1. 套接字：TCP套接字、UDP套接字、UNIX域套接字

1. 线程同步
    1. 互斥锁，用来保护临界区，保证任意时刻只有一个线程在执行其中的代码。互斥
       锁只能用来上锁不能用来等待
    2. 条件变量：`pthread_cond_signal`函数用来唤醒等待在相应条件变量上的一个线
       程或者用`pthread_cond_broadcast`唤醒阻塞在相应条件变量上的所有线程
    3. 读写锁
        - 获取一个读写锁用于读叫做共享锁，其他线程也可以读
        - 获取一个读写锁用于写叫做独占锁，其他线程不能访问或修改
    4. 记录上锁，可用于进程间共享某个文件的读与写，应用会指定文件中待上锁或解
       锁的字节范围
    5. 信号量，用于提供不同进程间或一个给定进程的不同线程间同步手段的原语，通
       过原子的PV操作来增加或减少信号量
        - `sem_wait`函数测试信号量的值，如果大于0就减一并返回，否则使线程处于
          休眠状态
        - 线程使用完某个信号量调用`sem_post`使该信号量的值加1
    6. 屏障，当一个进程到达屏障时会被屏障拦住，直到所有进程都到达该屏障为止

1. `fork`和`vfork`的区别
    - 一个进程可以调用`fork`函数创建一个新的进程，`fork`函数被调用一次会返回两
      次，子进程的返回值是0（一个子进程只有一个父进程，可以通过`getpid`获得父
      进程的进程ID，而ID 0总是由内核交换进程使用），父进程的返回值是新建子进程
      的进程ID。然后子进程和父进程继续执行`fork`调用后的指令。子进程是父进程的
      副本，获得父进程数据空间、堆和栈的副本。现在很多实现使用了写时复制(COW)
      技术，数据段、堆栈由父进程和子进程共享，而且内核将它们的访问权限变为只读。
      如果父进程和子进程中的任意一个试图修改这些区域，内核只为修改区域的那块内
      存制作一个副本，通常是虚拟内存的一页。
    - `vfork`用于创建一个新进程来执行一个新程序。`vfork`创建一个子进程但是不会
      把父进程的地址空间完全复制到子进程中，因为子进程会立即调用`exec`从而不会
      引用该地址空间。在调用`exec`之前，子进程在父进程的空间中运行。`vfork`保
      证子进程先运行，在调用`exec`或`exit`后父进程才可能被调度运行。

1. `wait`和`waitpid`的作用
    - 如果其所有的子进程都还在运行，则阻塞
    - 如果一个子进程已终止，正等待父进程获取其终止状态，则取得该子进程状态立即
      返回
    - 如果没有子进程，出错返回
    - `waitpid`可使调用者不阻塞，且并不等待其调用第一个终止的子进程

1. 什么是系统调用
    - 系统调用指运行在用户空间的程序向操作系统内核请求需要更高权限运行的服务。
    - 系统调用提供用户程序与操作系统之间的接口

1. 系统调用的过程
    1. 应用程序调用库函数
    1. 库函数将系统调用号存入eax，然后通过中断使系统进入内核态
    1. 内核中的中断处理函数根据系统调用号，调用对应的内核函数
    1. 系统调用完成相应功能，将返回值存入eax，返回中断处理函数
    1. 中断处理函数返回到库函数
    1. 库函数将eax中的返回值返回给应用程序

1. 函数调用的过程
    栈保存了函数调用所需要维护的信息，包括函数的参数和返回地址，临时变量和保存
    的上下文即相关的寄存器。一个函数的堆栈帧由ebp和esp划定范围，esp始终指向栈
    顶，ebp一般指向保存上一个ebp内容的地址。当一个函数调用发生时
    1. 将所有或者一部分参数压入栈中，如果有其他参数没有入栈，就用特殊的寄存器
       传递
    2. 将当前指令的下一条指令的地址压入栈中
    3. 跳转到函数体执行
    4. 将ebp压入栈中
    5. 使ebp指向栈顶
    6. 将寄存器压入栈中
    7. 恢复保存的寄存器
    8. 恢复esp同时回收局部变量的空间
    9. 从栈中恢复保存的ebp的值
    10. 从栈中取得返回地址，并跳转到该位置

1. 中断处理流程

1. 什么是死锁

    如果一个进程集合中的每个进程都在等待只能由该进程集合中的其他进程才能引发的事件，
    那么该进程集合就是死锁的

1. 资源死锁的发生条件

    - 互斥条件。每个资源要么已经分配给了一个进程，要么就是可用的
    - 占有和等待条件。已经得到了某个资源的进程可以再请求新的资源
    - 不可抢占条件。已经分配给一个进程的资源不能强制性地被抢占
    - 环路等待条件。死锁发生时，系统中一定有两个或以上的进程组成的一条环路，其
      中的每个进程都在等待下一个进程所占有的资源

1. 怎么检测死锁

    1. 用圆形代表进程，方形代表资源，进程到资源的箭头代表进程在请求该资源，资
       源到进程的箭头代表资源被该进程所占有。由此可以画出对应的资源分配图，图
       中如果包含环路则代表有死锁。因此可以使用有向图的环路检测算法来检测死锁
          - 拓扑排序法
              1. 将所有入度为0的结点放入队列
              1. 队列不为空时，弹出队首元素，并将队首元素指向的相邻结点的入度
                 减1，且将入度变为0的结点放入队列
              1. 循环结束时如果已经访问过的结点数不等于结点总数，则有环
          - DFS，深度优先遍历图，如果遍历的过程中，发现某个结点有一条边指向已
            经访问过的结点则有环
          - 并查集
              1. `parent[i]`表示结点i所在的集合，初始值为-1
              1. 遍历边，对边i->j来说，如果`parent[i] == j`则说明有环
              1. 否则将parent[j]设置为i，同时进行路径压缩
    1. E表示现有资源向量，A表示可用资源向量，C表示当前分配矩阵，R表示请求分配
       矩阵，即
        - E[i]表示资源i的数量
        - A[i]表示可用资源i的数量
        - C[i][j]表示进程i已经分配的资源j的数量
        - R[i][j]表示进程i正在请求的资源j的数量

       则死锁检测算法如下：
        - 初始所有进程都是未标记的，标记的进程表示它们可以执行不会陷入死锁
        - 寻找一个没有标记的进程P[i]，满足R[i] <= A
        - 如果找到，则将C[i]加到A上，标记该进程，返回上一步
        - 否则算法终止，未标记的进程都是死锁进程

1. 怎么从死锁中恢复
    1. 利用抢占恢复，临时将某个资源从当前所有者转移到另一个进程
    1. 利用回滚恢复，周期性地对进程进行检查点检查，即将进程的状态写入一个文件。
       检查点中包括存储映像，资源状态。新的检查点写入新的文件。当检测到死锁时，
       从一个较早的检查点恢复持有相关资源的进程
    1. 杀死进程恢复，杀掉环路中的一个进程，该进程应正好持有环中某些进程所需要
       的资源

1. 银行家算法
    - 安全状态：即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能
      够使得每个进程运行完毕。
    - 银行家算法对每个请求进行检查，如果这一请求能达到安全状态则满足这一请求
    - E表示现有资源向量，A表示可用资源向量，C表示当前分配矩阵，R表示请求分配
       矩阵，即
        - E[i]表示资源i的数量
        - A[i]表示可用资源i的数量
        - C[i][j]表示进程i已经分配的资源j的数量
        - R[i][j]表示进程i正在请求的资源j的数量
    - 算法流程
        1. 查找请求分配矩阵中是否存在i满足R[i] <= A
        1. 如果不存在这样的行则系统会发生死锁
        1. 否则可以假设该进程获得所需的资源并运行结束释放了资源，将C[i]加到A上
           将进程标记为终止
        1. 重复上面的步骤直到所有进程标记为终止，则其状态是安全的

1. 死锁预防
    - 破坏互斥条件，比如打印机，唯一真正请求使用物理打印机的是打印机守护进程，
      其他请求使用打印机的通过采用假脱机打印机产生同时产生输出
    - 破坏占有并等待条件
        1. 所有进程在开始执行前请求所需的所有资源（有时候并不知道需要多少资源，
           以及知道了就可以使用银行家算法了）
        1. 当一个进程请求资源时，先暂时释放其当前占有的所有资源，然后再尝试获
           取所有的资源
    - 破坏不可抢占条件，通过虚拟化技术
    - 破坏环路等待条件
        1. 每个进程在任何时刻都只能占用一个资源，如果要请求另外一个资源，必须先
           释放第一个资源
        1. 所有资源统一编号，所有请求必须按照资源编号的顺序提出
        1. 所有资源统一编号，不允许进程请求比当前所占资源编号低的资源

## 内存

1. 什么是地址空间

    地址空间是一个进程可用于寻址内存的一套地址集合。每个进程都有一个自己的地址
    空间，并且这个地址空间独立于其他进程的地址空间

1. 空闲内存管理技术
    1. 位图法，内存被分为固定大小的分配单元，每个分配单元对应位图中的一位，0表
       示空闲，1表示占用
    1. 链表法，维护一个记录已分配内存段和空闲内存段的链表，链表中的一个结点或
       者是包含一个进程，或者是两个进程间的一块空闲区。即每个结点包含空闲区或
       进程的指示标志，起始地址，长度和指向下一结点的指针。分配内存的算法有
        - 首次适配，沿着段链表进行搜索，直到找到一个足够大的空闲区，并将空闲区
          分成两部分，一部分供进程使用，另一部分形成新的空闲区
        - 下次适配，和首次适配法类似，不同的是每次找到合适的空闲区时记录当时的
          位置，下次从上次结束的地方开始搜索
        - 最佳适配，找出能容纳进程的最小的空闲区（会产生很多碎片）
        - 最差适配，总是分配最大的空闲区
        - 快速适配，为常用大小的空闲区维护单独的链表（类似malloc）

1. 伙伴算法
    1. 初始内存由一块连续的片段组成，当一个内存请求到达时，上舍到2的幂，不断将
       低段的内存块二分，直到出现刚好能容纳该内存请求的块
    2. 后续到达的请求同样上舍到2的幂，如果有空闲的刚好能容纳该请求的块直接分配
       给该请求，否则从低空闲段开始分裂直到找到合适的块
    3. 同一个块分裂出去的两个块如果都被释放了则合并它们

1. slab分配器

    伙伴算法会生成大量的碎片，slab分配器使用伙伴算法来获得内存块，但是并不是直
    接使用而是从中切出slab并分别进行管理。对于某一类型比如`task_struct`，slab
    分配器为其设置相应的对象缓存，这些缓存由一个或多个slab指针组成，每个slab能
    存储大量相同类型的的对象。当内核需要为该类型的对象分配内存时，会在对象缓存
    中寻找一个部分满的slab将对象放入其中，如果必要，也会分配一个新的slab来存放
    该对象。

1. 什么是虚拟内存

    虚拟内存为每个进程提供一种假象，每个进程都有独立的，私有的，连续的地址空间。
    这个空间被分割成多个块，每一块称为一页。每一页有连续的地址范围。这些页被映
    射到物理内存，但并不是所有的页都必须在内存中才能运行程序。当程序引用到一部
    分在物理内存中的地址空间时，由MMU立即执行虚拟内存地址到物理内存地址的映射；
    当引用到不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存
    并重新执行失败的指令。

1. 虚拟内存的优缺点
    - 优点
        - 每个程序都有一个从0开始的虚拟内存地址空间，大大简化了编程，因为不需
          要再手动维护内存地址的偏移
        - 即使物理内存地址不连续，虚拟内存也可以做到虚拟内存地址连续，即将物理
          内存碎片拼到一起使用，减小了内存碎片
        - 解决了物理内存有限的问题，操作系统可以给每个进程分配比实际内存大的多
          的虚拟内存空间
        - 提高了CPU利用率和吞吐量，因为只有在需要的时候才将相应的页面装入内存，
          这样每个程序不必完全处于内存中，需要的实际内存大大减少从而同一时间可
          以运行更多程序
        - 虚拟内存通过分页实现了内存保护机制，用户程序不能修改只读的页面，不能
          访问和修改内核中的代码和数据，也不能访问私有的以及其他进程的内存
        - 虚拟内存允许文件和内存通过共享页被多个进程共享，使得多个进程可以共享
          一个系统库，以及通过共享内存来实现进程间的通信
    - 缺点
        - 虚拟内存一般通过分页来管理内存，因此会生成页表，页表会占用内存，缺页
          和页面置换都会产生磁盘I/O增加额外的负担

1. 虚拟内存地址的翻译过程

    操作系统通过内存管理单元MMU和页表将虚拟内存地址翻译为物理内存地址。MMU是处
    理器的一个硬件单元，通常每个核有一个MMU，MMU由两部分组成，TLB和table walk
    unit。页表记录了虚拟页面到页框的映射，每个表项记录了页框号和访问位、修改位、
    保护位以及present位。虚拟地址可以被分为两部分，高位表示页表项的索引，低位
    表示页偏移，即VPN和VPO。

    翻译虚拟内存地址时，首先在TLB中查找。TLB实际是页表的一个缓存，缓存的每一行
    包括一个TLB tag，权限位，有效位，保护位和页框号。VPN根据TLB的行数划分为tag
    和TLB索引，MMU同时将VPN中的tag与TLB中每一行的tag比较，如果tag一致，且有效
    位是有效的且通过保护性检查则直接取出页框号不用再去访问页表。

    否则去页表中查询，如果页面在内存中则更新TLB，进行保护性检查，取出页框号。
    否则产生一个页错误，去磁盘中将对应的页面调入内存。出现页错误有两种情况：

    1. 这个虚拟地址被分配后还没有被访问过，触发页错误后分配物理内存
    1. 对应的物理页面被换出到外部磁盘了，将其换回物理内存，再次建立映射，然后
       将保护位置1

    当保护性检查不通过时，会产生段错误，即访问权限冲突。

1. 最近未使用(NRU)页面置换算法

    当发生缺页中断时，操作系统检查所有页面，并根据当前的R位和M位将页面分为4类
    - 第0类：没有被访问，没有被修改。
    - 第1类：没有被访问，已经被修改。
    - 第2类：已经被访问，没有被修改。
    - 第3类：已经被访问，已经被修改。

    算法随机地从类编号最小的非空类中挑选一个页面淘汰。（第1类在第2类前面隐含的
    意义是淘汰一个未访问的脏页面比淘汰一个经常使用的干净页面要好）

1. 先进先出页面置换算法

    由操作系统维护一个在内存中页面的链表，最新进入的页面放在表尾，最早进入的页
    面在表头。发生缺页中断时，淘汰表头的页面并把新调入的页面加入队尾。缺点是可
    能淘汰经常使用的页面。

1. 第二次机会页面置换算法

    基于FIFO算法，发生缺页中断时，检查表头的页面，如果R位为0则将其淘汰出内存，
    如果被修改过则将其写回磁盘。如果R位为1，则清楚R位并将其放到队尾。缺点是经
    常要在链表中移动页面。

1. 时钟页面置换算法

    基于第二次机会页面置换算法，不过是使用的环形链表，发生缺页中断时检查表针指
    向的页面，R为0则淘汰该页面并把新页面插入到当前位置，R为1则将表针指到下一个
    位置。

1. LRU算法

    发生缺页中断时，置换未使用时间最长的页面。需要在内存中维护一个所有页面的链
    表，最近最多使用的页面在表头，最近最少使用的在表尾。每次访问内存都要更新链
    表，在链表中找到对应的页面将其移到表头，这个操作非常费时。

    偶发性、周期性的批量查询操作会淘汰大量热点数据。

    优化时间复杂度。使用hash表保存键到双向链表中结点的映射

1. LFU算法

    发生缺页中断时，淘汰最少使用的页面，如果使用频率一致则淘汰最长时间未使用的。
    与LRU类似，可以用hash表保存键到结点的映射。访问和修改时更新使用频率和时间。
    也可以使用双hash表，一个保存频率到双向链表的映射，另一个保存键到结点的映射。

1. 大页面和小页面

    - 大页面会造成更大的内部碎片，但是可以节省传输页面的时间，大小页面在内存与
      磁盘间的传输时间几乎一样，大页面还拥有更小的页表
    - 小页面内部碎片的浪费更少，但生成的页表更大。

1. 页面清除策略

    为保证有足够的空闲页框，很多分页系统有一个分页守护进程的后台进程，定时唤醒
    并检查内存的状态，如果空闲页框过少，则通过预定的页面置换算法选择页面换出内
    存。这是因为保存一定数目的页框供给比使用所有内存并在需要时搜索一个页框有更
    好的性能。

1. 进程创建、执行、终止时与分页有关的工作

    - 进程创建时，首先确定程序和数据的初始大小，为其创建页表，然后操作系统在内
      存中给页表分配空间并初始化。操作系统还需要在磁盘交换区中分配空间以便进程
      换出时在磁盘上有放置该进程的空间。同时要用程序正文和数据对交换区进行初始
      化，这样发生缺页中断时可以调入需要的页面。最后操作系统将页表和磁盘交换区
      相关的信息存储在进程表中
    - 调度一个进程执行时，必须为新进程重置MMU，刷新TLB，切换全局页表。
    - 进程退出时，操作系统要释放进程的页表、页面和页面在磁盘上占用的空间

1. 缺页中断的过程
    1. 硬件陷入内核，在堆栈中保存程序计数器。
    1. 启动一个汇编代码例程保存通用寄存器和其他易失信息。
    1. 通过硬件寄存器找出中断时需要的虚拟页面
    1. 一旦知道了发生缺页中断的虚拟地址，操作系统检查该地址的有效性以及存取与
       保护是否一致。如果不一致，向进程发送一个信号或杀死进程。如果有效且没有
       保护错误发生，系统检查是否有空闲页框，如果没有，执行页面置换算法寻找一
       个页面来淘汰
    1. 如果选择的页面已被修改过，安排该页写回磁盘，并发生一次上下文切换，挂起
       产生缺页中断的进程，让其他进程运行直到磁盘传输结束。此时该页框被标记为
       忙，以免被其他进程占用。
    1. 页框如果是干净的，操作系统查找所需页面在磁盘上的地址，将其装入页框。装
       入时该进程仍然被挂起。
    1. 当磁盘中断发生时表明该页面已装入，页表可以更新映射反映它的位置，页框也
       被标记为正常状态。
    1. 恢复发生缺页中断指令以前的状态，程序计数器重新指向这条指令。
    1. 调度引发缺页中断的进程，操作系统返回调用它的汇编语言例程
    1. 该例程恢复寄存器和其他状态信息，返回到用户空间继续执行

## I/O

1. I/O多路复用

    单线程或单进程同时检测若干个文件描述符是否可以执行操作。使用更少的资源完成
    更多的事。

    阻塞I/O，发起一次I/O操作后需等待其成功或失败，期间程序不能做其他事情，只能
    对单个文件描述符操作。

    非阻塞I/O，通过O_NONBLOCK来指定I/O操作为非阻塞的，如果操作不能完成，则调用
    立即出错返回，只能对单个文件描述符操作。

    I/O多路复用，select、poll、epoll，对一组文件描述符进行相关事件的注册，然后
    阻塞等待某些事件的发生或超时。

    信号驱动I/O，利用信号机制，让内核通知应用程序文件描述符的相关事件

    异步I/O，和信号驱动I/O类似，完成了数据的拷贝后才通知程序处理

    select维护三组文件描述符，分别是关心的可读、可写或处于异常条件的描述符的集
    合，返回已经准备好的描述符的数量。主要缺点是监控的文件描述符数量有限制，以
    及每次调用都要从用户空间把描述符集合拷贝到内核空间，以及轮询效率低下。

    poll和select类似，不过只有一个pollfd数组，每个元素表示一个需要监听I/O操作
    事件的文件描述符。返回准备就绪的数量。相比select只解决了文件描述符数量限制
    的问题。

    epoll采用红黑树方式管理socket描述符，降低了添加、删除描述符的复杂度。epoll
    在内核空间建立红黑树，减少了从用户空间到内核空间的拷贝开销。epoll还在内核
    中维护了一个就绪链表。水平触发返回就绪链表中的所有描述符，边缘触发用于检查
    某个描述符是否已经就绪。

    epoll使用一个文件描述符管理多个描述符，将用户关心的文件描述符的事件存放到
    内核的一个事件表中，这样在用户空间和内核空间的拷贝只需要一次。epoll支持水
    平触发和边缘触发，边缘触发会通知进程哪些文件描述符刚变成了就绪态，且只会通
    知一次。epoll采用事件进性通知，通过`epoll_ctl`注册描述符，一旦该描述符就绪，
    内核会采用类似回调函数的机制来激活该描述符，`epoll_wait`就可以收到通知。
    优点：
        - 没有最大并发连接的限制
        - 不是轮询的方式，效率提升

1. 程序内存模型

